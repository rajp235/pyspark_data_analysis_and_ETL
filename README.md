# pyspark_data_analysis_and_ETL

This project analyzes a coffee survey dataset in order to extract insight into determining if there are any interesting relationships and correlations between certain variables. The tools utilized in this project include PySpark - Spark is a multi-purpose tool for executing data engineering, data science, and machine learning tasks. PySpark is the Python interface to Spark and involves manipulating data, in this case, through the Spark DataFrames object. It also allows for utilizing SQL statements via Spark SQL.

There is also an ETL process (Extract, Transform, Load) developed in this project that allows the merging of data from two datasets in order to create a new dataset that can be utilized to recommend specific coffee shops in New York based on the coffee preferences of the age group. This could potentially be implemented in recommendation engines or data profiling.
